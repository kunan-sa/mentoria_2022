{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tFkXu9PjWgtf"
   },
   "source": [
    "# **Práctico N°3**           **Introducción al aprendizaje automático**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "l6dsCC0tg7aT"
   },
   "source": [
    "## Objetivo y alcance\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aM9VAmMT4WiY"
   },
   "source": [
    "Para esta materia el objetivo es poder hacer un primer acercamiento a un proceso de aprendizaje automático,Nos enfocaremos en el en el proceso de: planteo de preguntas de investigación, selección de un modelo, ajuste de hiperparámetros y evaluación,regulador, métricas, similar a lo que hicieron en el segundo laboratorio de esta materia.\n",
    "En este laboratorio no se espera que se encuentre el mejor modelo con sus mejores parámetros, sino que se logre la buena práctica de realizar los pasos necesarios en un proceso de aprendizaje automático, desde el planteo de pregunta de investigación, hasta la división del dataset hasta la evaluación del modelo. Para realizar el práctico vamos a utilizar los datasets generados en la materia anterior. \n",
    "\n",
    "\n",
    "## **Planteo del problema**\n",
    "La primera actividad será plantear un problema de investigación. Como inspiración pueden elegir alguno de los problemas planteados por los dos grupos durante los últimos prácticos, alguno de los que propongo yo o uno nuevo que propongan ustedes.\n",
    "\n",
    "### Planteados por los grupos\n",
    "Los dos grupos plantearon los siguientes problemas de investigación\n",
    "\n",
    "**grupo 1**\n",
    "- Predecir días hasta el turno: A la hora de dar las opciones de horarios de un turno, sería informativo para el paciente saber la distancia aproximada de días hasta conseguir un turno asignado. Para ello se debería armar un modelo que dado un nombre de hospital y una especialidad devuelva una cantidad de días de turno y una confianza en la predicción.\n",
    "\n",
    "**grupo 2**\n",
    "- Presencia de emergencia en una conversación: Debería haber un tratamiento diferencial para las urgencias?\n",
    "- predecir presencia de disconformidad en una conversación. Qué situaciones, respuestas, contextos provocan mayor disconformismo en los usuarios?\n",
    "\n",
    "**Otras propuestas**\n",
    "- Tanto emergencia como disconformidad pueden tratarse junto con presencia de errores, no_correlation y largo de una conversación como un mismo tag Situación_Crítica, y predecir si una conversación llegará a ese estado.\n",
    "- Dada la presencia del tag Human_HH podemos intentar predecir si una conversación terminará en HH o no.\n",
    "\n",
    "**Más ideas:**\n",
    "- Entrenar un modelo generador de respuestas. Está bueno como ejemplo de procesamiento https://towardsdatascience.com/training-your-own-message-suggestions-model-using-deep-learning-3609c0057ba8 \n",
    "\n",
    "**Referencias:**\n",
    "- tokenización: https://neptune.ai/blog/tokenization-in-nlp\n",
    "- encoding: https://machinelearningmastery.com/how-to-prepare-categorical-data-for-deep-learning-in-python/\n",
    "\n",
    "### **Para ello se debe:**\n",
    "\n",
    "* Elijan/armen un dataset que les sirva para responder la pregunta de investigación que se plantearon. Pueden partir de los datasets que armó cada grupo en el práctico anterior.  <--- darselos para que tengan un paso menos\n",
    "* Crear/Identificar una variable que responda a la demanda. <-- darles la variable identificada\n",
    "* Dependiendo de la tarea elegida, deberán hacer uso de alguna técnica de encoding/tokenización (ver referencias y ejemplos de la sección Más ideas) para poder usar los datos de Body. spaCY tiene soporte para estas tareas en español.\n",
    "* Cargar los datos, separando del dataset la etiqueta a predecir.\n",
    "* Dividir el dataset en el conjunto de entrenamiento y conjunto de test\n",
    "* Analizar y justificar que features se utilizarán para lograr la mejor predicción.\n",
    "* Elegir dos modelos de clasificación (uno por cada requerimiento). Los que Uds. se sientan más cómodos, pero también justificando conceptualmente la elección de la función de regularización.\n",
    "* Entrenar y evaluar los modelos, fijando la semilla aleatoria para hacer repetible el experimento.\n",
    "* En cuanto a los hiper-parámetros:\n",
    "\n",
    "        1.   Probar primero con los default y elegir alguna/s métrica/s para reportar los resultados. \n",
    "        2.   Luego usar grid-search y 5-fold cross-validation para explorar muchas combinaciones posibles de valores, reportando  accuracy promedio y varianza para todas las configuraciones.\n",
    "\n",
    "*   Para la mejor configuración encontrada, evaluar sobre el conjunto de entrenamiento y sobre el conjunto de evaluación, reportando:\n",
    "        *   Accuracy\n",
    "        *   Precision\n",
    "        *   Recall\n",
    "        *   F1\n",
    "        *   Matriz de confusión\n",
    "\n",
    "### Se evaluarán los siguientes aspectos:\n",
    "  ***1-*** Que se apliquen los conceptos vistos con los profes en el teórico y en el práctico.\n",
    "\n",
    "  ***2-*** Que el entregable no sea solo la notebook. El informe debe tener un mensaje claro y debe presentarse en un formato legible para cualquier tipo de stakeholder.\n",
    "\n",
    "  ***3-*** Capacidad de análisis.\n",
    "\n",
    "  ***4-*** Criterio para elegir que solución aplicar en cada caso y con qué método implementarla.\n",
    "\n",
    "\n",
    "  \n",
    "## Deadline pautado para la entrega: Lunes 19/08/2022"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "N2uW9UYDWspO"
   },
   "source": [
    "### Se evaluarán los siguientes aspectos:\n",
    "Que se apliquen los conceptos vistos en el dictado de la materia.\n",
    "\n",
    "Que los cálculos estadísticos sean utilizados solo como herramientas para responder a las consignas.\n",
    "\n",
    "Indicar el criterio aplicado al momento de elegir las variables a analizar.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HzJ4l-qbpY1x"
   },
   "source": [
    "Es importante que vayan anotando **conclusiones y observaciones en lenguaje natural** (no muy extensas) a medida que vayan realizando las tareas para que les sirva como **punto de partida** para el video de 10 min que se realice a partir de este práctico. El video que sigue a este práctico serviría como informe de resultados y observaciones de este ejercicio.\n",
    "\n",
    "Lo importante de este práctico **no es encontrar el mejor modelo posible** ni mucho menos, sino poder ejercitar todo el proceso, que implica tanto preparar los datos hasta correr los experimentos, y finalmente analizar y explicar los resultados encontrados. En mi experiencia, la primera reacción ante saber que hay que comunicar resultados es querer comunicar éxitos, pero los resultados exitosos son -la mayoría de las veces- poco informativos. En el proceso de realización del práctico se encontrarán con desafíos de las tareas propuestas y con problemas específicos de este tipo de datasets conversacionales. Esa información es la valiosa a comunicar ya que es una experiencia que ningún otro grupo pudo tener, y le puede servir a otro grupo en un futuro que se relacione con datos que tengan características parecidas."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
