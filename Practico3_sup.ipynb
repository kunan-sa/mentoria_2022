{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tFkXu9PjWgtf"
   },
   "source": [
    "# **Práctico N°3**           **Aprendizaje supervisado**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "l6dsCC0tg7aT"
   },
   "source": [
    "## Objetivo y alcance\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aM9VAmMT4WiY"
   },
   "source": [
    "Para esta materia el objetivo es poder hacer un primer acercamiento a un proceso de aprendizaje supervisado.\n",
    "\n",
    "En este laboratorio no se espera que se encuentre el mejor modelo con sus mejores parámetros, sino que se logre la buena práctica de realizar los pasos necesarios en un proceso de aprendizaje supervisado, desde el entendimiento de la pregunta de investigación hasta la preparación de datos, desde la división del dataset hasta la evaluación del modelo. Para realizar el práctico vamos a utilizar el datasets que hayan generado en el práctico anterior.\n",
    "\n",
    "\n",
    "## Introducción\n",
    "En un mismo día une operadore humano de una clínica responde cientos de consultas sobre problemáticas increiblemente sensibles como lo es la salud de una persona y las preocupaciones relacionadas a eso. Además la demanda de trabajo de une operadore humano es multivariada y dinámica: algunos días hay un flujo mayor de pacientes usando los sistemas hospitalarios, y hay momentos del mes y del día en donde prácticamente no hay ninguna consulta a atender. \n",
    "\n",
    "El dato de **tiempo de respuesta de HH** tiene muchas implicaciones a nivel producto. Tener ese dato nos permite:\n",
    "- informarle a la persona usuaria el tiempo promedio de respuesta antes de pasarla a hablar con une operadore, para que adecúe sus expectativas a la realidad. \n",
    "- informarle detalladamente este dato a los hospitales como reporte de uso al final del mes, para que organice al grupo de trabajo eficientemente y con información veraz\n",
    "- permitir configurar lógicas automáticas de repartición de tareas para les operadores, para facilitarles su trabajo\n",
    "\n",
    "Por ello lo que se pretende en este práctico es poder armar un modelo que nos ayude a predecir el tiempo de respuesta de HH. Lo que nos da este dato es la presencia de la feature Got_HH, que cuando vale 1 nos marca en el dataset que el bot realizó la transferencia. El siguiente mensaje que tenga Direction == outbound sería el primer mensaje de un operador humano. La diferencia de horas entre estos dos mensajes nos da el tiempo de respuesta de un operador humano.\n",
    "\n",
    "Predecir esta variable teniendo en cuenta las distintas features del dataset será una tarea de regresión. Entrenar un modelo por hospital dará una mejor predicción. Por conocimiento del dataset sabemos que entrenar por porción del día (mañana/tarde) también dará mejores resultados, pero esto es opcional.\n",
    "\n",
    "## Tareas\n",
    "En orden,\n",
    "\n",
    "Deberán armar un dataset más pequeño que el actual, **sacando**:\n",
    "- las filas de los hospitales sin HH (Demo, Desarrollo, Clínica Carrá, Default) y las conversaciones sin HH (que agrupadas por conv_id no tengan un Got_HH == 1)\n",
    "- las conversaciones que nunca hayan pasado a HH (es decir Got_HH es 0 en toda la agrupación por conv_id) (guiarse con https://stackoverflow.com/questions/52393659/pandas-dataframe-check-if-column-value-exists-in-a-group-of-columns )\n",
    "- Para simplificar, las conversaciones que hayan pasado a HH pero el operador nunca respondió. Es decir Got_HH es 1 en alguna fila, pero no hay una fila siguiente con direction igual a outbound.\n",
    "\n",
    "**generar** las features:\n",
    "\n",
    "- tiempo_de_respuesta_HH (agrupando por conv_id, calcular el valor absoluto de la diferencia entre el SentDate del mensaje con Got_HH igual a 1 y el del siguiente mensaje con Direction igual a outbound https://stackoverflow.com/questions/34023918/make-new-column-in-panda-dataframe-by-adding-values-from-other-columns )\n",
    "- cant de mensajes de la conversación (agrupación por conv_id+dia y luego sum) (https://stackoverflow.com/questions/39922986/how-do-i-pandas-group-by-to-get-sum)\n",
    "- momento del dia (day_moment fue generada por el grupo 2 y puede reutilizarse el código que está aquí https://colab.research.google.com/drive/1KHgwiRqFLlavfhnCNdVvqG-xoPc0qMsM?usp=sharing#scrollTo=P04lwj2bSrFM )\n",
    "\n",
    "**manteniendo** las features:\n",
    "\n",
    "> - dia de la semana\n",
    "> - fecha\n",
    "> - presencia de errores en la conversación\n",
    "> - hospital\n",
    "> - cancelled\n",
    "> - consulted\n",
    "> - no correlation\n",
    "> - y en general, todas las features que no sean body ni direction.\n",
    "> - Debiendo quedar una fila por conversación.\n",
    "\n",
    "* Cargar los datos, separando del dataset la etiqueta a predecir.\n",
    "* Dividir el dataset en el conjunto de entrenamiento y conjunto de test\n",
    "* Elegir y fundamentar si usar regresión lineal o polinomial(https://towardsdatascience.com/introduction-to-linear-regression-and-polynomial-regression-f8adc96f31cb, https://data36.com/polynomial-regression-python-scikit-learn/ ) . Tomarse un tiempito en hacer esta decisión les será muy útil ya que es una decisión interesante para comunicar en el video que tengan que hacer a partir de este práctico.\n",
    "* Entrenar y evaluar un modelo de regresión lineal y uno polinomial, fijando la semilla aleatoria para hacer repetible el experimento.\n",
    "* En cuanto a los hiper-parámetros:\n",
    "\n",
    "        1.   Probar primero con los default y elegir alguna/s métrica/s para reportar los resultados. \n",
    "        2.   Luego usar grid-search (https://machinelearningmastery.com/hyperparameter-optimization-with-random-search-and-grid-search/) para explorar muchas combinaciones posibles de valores (Ejemplo de uso de grid search para encontrar el grado de polynomial regression https://stackoverflow.com/a/62460485/13597482 ). Reportar MAE y RMSE para las variaciones que busquen.\n",
    "\n",
    "*   Para la mejor configuración encontrada, evaluar sobre el conjunto de entrenamiento y sobre el conjunto de evaluación, reportando MAE y RMSE.\n",
    "\n",
    "### Se evaluarán los siguientes aspectos:\n",
    "  ***1-*** Que se apliquen los conceptos vistos con los profes en el teórico y en el práctico.\n",
    "\n",
    "  ***2-*** Capacidad de análisis. Enfocarse en esto les permitirá completar el video que deben preparar a continuación.\n",
    "\n",
    "  ***3-*** Criterio para elegir que solución aplicar en cada caso y con qué método implementarla.\n",
    "\n",
    "\n",
    "  \n",
    "## Deadline pautado para la entrega: Miércoles 21/08/2022"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HzJ4l-qbpY1x"
   },
   "source": [
    "Es importante que vayan anotando **conclusiones y observaciones en lenguaje natural** (no muy extensas) a medida que vayan realizando las tareas para que les sirva como **punto de partida para el video** de 10 min que se realice a partir de este práctico. El video que sigue a este práctico serviría como informe de resultados y observaciones de este práctico, resaltando aprendizajes y problemáticas con las que se hayan encontrado.\n",
    "\n",
    "Lo importante de este práctico **no es encontrar el mejor modelo posible** ni mucho menos, sino poder ejercitar todo el proceso, que implica tanto **preparar los datos hasta correr los experimentos**, y finalmente **analizar y explicar los resultados encontrados**. En mi experiencia, la primera reacción ante saber que hay que comunicar resultados es querer comunicar éxitos, pero los resultados exitosos son -la mayoría de las veces- poco informativos. En el proceso de realización del práctico se encontrarán con desafíos de las tareas propuestas y con problemas específicos de este tipo de datasets conversacionales. Esa información es la valiosa a comunicar ya que es una experiencia que ningún otro grupo pudo tener, y le puede servir a otro grupo en un futuro que se relacione con datos que tengan características parecidas."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
